import matplotlib.pyplot as plt
import mlflow
import pandas as pd
import seaborn as sns
from mlflow.tracking import MlflowClient

# Set style
plt.style.use("seaborn-v0_8-darkgrid")
sns.set_palette("husl")

# Initialize client
client = MlflowClient()

# Get experiment
experiment = client.get_experiment_by_name("hateful-memes-comparison")

# Fetch all runs
runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])

# Filter for completed runs
completed_runs = runs[runs["status"] == "FINISHED"]

# Group by model architecture
model_comparison = (
    completed_runs.groupby("tags.model_architecture")
    .agg(
        {
            "metrics.val_accuracy": ["mean", "std", "max"],
            "metrics.val_precision": ["mean", "std", "max"],
            "metrics.val_recall": ["mean", "std", "max"],
            "metrics.val_f1": ["mean", "std", "max"],
            "metrics.val_auc": ["mean", "std", "max"],
        }
    )
    .round(4)
)

print("Model Performance Comparison:")
print(model_comparison)

# Visualizations
fig, axes = plt.subplots(2, 3, figsize=(18, 12))

metrics = ["val_accuracy", "val_precision", "val_recall", "val_f1", "val_auc"]
models = ["vilbert", "visualbert", "clip"]

for idx, metric in enumerate(metrics):
    ax = axes[idx // 3, idx % 3]

    # Get data for each model
    metric_data = []
    for model in models:
        model_runs = completed_runs[completed_runs["tags.model_architecture"] == model]
        metric_data.append(model_runs[f"metrics.{metric}"].values)

    # Create box plot
    bp = ax.boxplot(metric_data, labels=models)
    ax.set_title(f"{metric.replace('_', ' ').title()}")
    ax.set_ylabel("Score")
    ax.grid(True, alpha=0.3)

plt.suptitle("Model Performance Comparison - Hateful Memes Classification", fontsize=16)
plt.tight_layout()
plt.show()

# Best performing model
best_run = completed_runs.loc[completed_runs["metrics.val_auc"].idxmax()]
print(f"\nBest Model: {best_run['tags.model_architecture']}")
print(f"Best AUC: {best_run['metrics.val_auc']:.4f}")
print(f"Run ID: {best_run['run_id']}")
